{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5397cabe-b833-464c-a225-528bd973ab85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.18.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep-learning-env/lib/python3.9/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/envs/deep-learning-env/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <4C793A59-B32A-3AF1-BEA5-03AD7C5C80C6> /opt/anaconda3/envs/deep-learning-env/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/opt/anaconda3/envs/deep-learning-env/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/deep-learning-env/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/deep-learning-env/lib/python3.9/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/deep-learning-env/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.6.0.dev20241112\n",
      "transformers version: 4.46.3\n"
     ]
    }
   ],
   "source": [
    "# notebooks/helm_experiments.ipynb\n",
    "import IPython\n",
    "print(IPython.__version__)  # Check your IPython version\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, AutoConfig\n",
    "import json\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "import lm_eval\n",
    "from lm_eval import evaluator, tasks, utils\n",
    "from lm_eval.api.model import LM\n",
    "from lm_eval.api.registry import register_model\n",
    "from lm_eval.tasks import get_task_dict\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import ftfy\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "from itertools import zip_longest\n",
    "\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"transformers version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ffd9bf-08f9-4273-91d5-c860d383bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../')\n",
    "from data.config import BenchmarkConfig, DatasetConfig\n",
    "from data.data import DatasetManager, ModelDataset\n",
    "from data.metrics import BenchmarkMetrics\n",
    "from models.h2o.h2o_gptneox import GPTNeoXAttention_Mask, convert_kvcache_gpt_neox_heavy_recent\n",
    "from models.h2o.h2o_llama import LlamaAttention_heavy_hitter, convert_kvcache_llama_heavy_recent\n",
    "from models.h2o.h2o_opt import OPTAttention_Mask, convert_kvcache_opt_heavy_recent\n",
    "from models.base_models import ModelLoader\n",
    "from tests.run_benchmark import run_benchmark, run_helm_benchmark\n",
    "from scripts.run_helm import run_experiment\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bbf500c-db5f-4704-9f7b-38267ef25683",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    input_path: str\n",
    "    output_path: str\n",
    "    model_name: str\n",
    "    model_arch: str\n",
    "    cache_dir: str = \"./cache\"\n",
    "    heavy_ratio: float = 0.1\n",
    "    recent_ratio: float = 0.1\n",
    "    enable_small_cache: bool = True\n",
    "    sample_num: int = 10  # Start with a small sample size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a92e5a49-b9c5-4c1a-9ffd-af4c77e26022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GPT-NeoX\n",
    "args = Args(\n",
    "    input_path=\"data/xsum/xsum.jsonl\",\n",
    "    output_path=\"results/xsum-gptneox-test.jsonl\",\n",
    "    model_name=\"EleutherAI/gpt-neox-20b\",\n",
    "    model_arch=\"gpt_neox\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12436579-663d-400f-9ab8-a8b47c6e3707",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(\n",
    "    input_path=\"data/xsum/xsum.jsonl\",\n",
    "    output_path=\"results/xsum-llama2-test.jsonl\",\n",
    "    model_name=\"meta-llama/Llama-2-7b-hf\",\n",
    "    model_arch=\"llama\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1395e4e-78f1-4cfd-a428-1f92d5c44624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03:09:25:39,962 INFO     [run_helm.py:17] Using device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c780289085425a82a9a797aff73f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03:09:25:40,879 INFO     [run_helm.py:41] Enabling H2O Cache\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/xsum/xsum.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/llm-training/liquid-fusion/notebooks/../scripts/run_helm.py:52\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Load requests\u001b[39;00m\n\u001b[1;32m     51\u001b[0m requests \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstrip():\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/xsum/xsum.jsonl'"
     ]
    }
   ],
   "source": [
    "run_experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ad428-e2fe-48e7-9e14-9b0682343583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dlenv)",
   "language": "python",
   "name": "dlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
